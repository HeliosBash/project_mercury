#!/bin/bash

while [ $# -gt 0 ] ; do
        case "$1" in
                --node*|-n*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        node="${1#*=}"
                        ;;
                --sourceid*|-i*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        sid="${1#*=}"
                        ;;
                --timezone*|-z*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        timezone="${1#*=}"
                        ;;
                --startdatetime*|-s*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        startdatetime="${1#*=}"
                        ;;
                --enddatetime*|-e*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        enddatetime="${1#*=}"
                        ;;
                --latitude*|-a*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        lat="${1#*=}"
                        ;;
                --longitude*|-o*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        long="${1#*=}"
                        ;;
                --energyspike*|-g*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        energyspike="${1#*=}"
                        ;;
                --api*|-p*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        solcast_api_token="${1#*=}"
                        ;;
                --token*|-k*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        token="${1#*=}"
                        ;;
                --secret*|-c*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        secret="${1#*=}"
                        ;;
                --help|-h)
                        echo -n "Usage: solnet-filler [--help|-h] --node|-n [NODE] --sourceid|-i [SOURCE ID] --timezone|-z [TIMEZONE]"
                        echo -n "--startdate|-s [STARTDATETIME in \"YYYY-MM-DD HH:MM\"] --enddatetime|-e [ENDDATETIME "
                        echo -n "in \"YYYY-MM-DD HH:MM\"] --latitude|-a [LATITUDE] --longitude|-o [LONGITUDE] "
                        echo -n "--energyspike|-g [ENERGY SPIKE IN watthours] --api|-p [SOLCAST API TOKEN] --token|-k "
                        echo "[SOLNET TOKEN] --secret|-c [SOLNET SECRET]"
                        exit 0
                        ;;
                *)
			>&2 echo -n "Error: The following arguments are required --node --sourceid --timezone --startdatetime "
                        echo "--enddatetime --latitude --longitude --energyspike --api --token --secret. For PYR Fills, set energyspike to 0"
                        exit 1
                        ;;
        esac
        shift
done

if [[ -z "$node" || -z "$sid" || -z "$timezone" || -z "$startdatetime" || -z "$enddatetime" || -z "$lat" || -z "$long" || -z "$energyspike" \
        || -z "$solcast_api_token" || -z "$token" || -z "$secret" ]] ; then

        echo -n "Error: The following arguments are required --node --sourceid --timezone --startdatetime --enddatetime --latitude "
        echo "--longitude --energyspike --api --token --secret. For PYR Fills, set energyspike to 0" | tee -a $log_path

else
	sourceids=$(echo $sid | sed "s/\//%2F/g")
        runtime=$(date +"%Y%m%d_%H%M%S")
        log_path="data/solnet-filler-${runtime}.log"
        maxoutput=1000000


	if [[ "$sourceids" == *"GEN"* ]] || [[ "$sourceids" == *"PYR"* ]] ; then
		if [[ "$sourceids" == *"GEN"* ]] && [ $energyspike == 0 ] ; then
                        echo "$(date +'%Y-%m-%d %H:%M:%S') For GEN Fills, energyspike should be greater than 0"
		else
			echo -n "$(date +'%Y-%m-%d %H:%M:%S') Executed: /bin/bash solnet-filler --node $node --sourceid $sid " | tee -a $log_path
                        echo -n "--timezone $timezone --startdatetime $startdatetime --enddatetime $enddatetime " | tee -a $log_path
                        echo -n "--latitude $lat --longitude $long --energyspike $energyspike " | tee -a $log_path
                        echo    "--api $solcast_api_token --token $token --secret $secret" 2>&1 | tee -a $log_path

			# Check timezone format if its valid

		        check_timezone=$(awk '/^Z/ { print $2 }; /^L/ { print $timezone }' /usr/share/zoneinfo/tzdata.zi | grep -w $timezone)

        		while [ -z "$check_timezone" ]
        		do
                		echo -n "$(date +'%Y-%m-%d %H:%M:%S') Not a valid timezone. Enter timezone:  "
                		read timezone < /dev/tty
                		check_timezone=$(awk '/^Z/ { print $2 }; /^L/ { print $timezone }' /usr/share/zoneinfo/tzdata.zi | grep -w $timezone)
        		done
			
			# Sets the entered date to local and converts it to utc

			#echo $startdatetime
		        localstartdate=$(TZ=$timezone date -d "$startdatetime" )
        		localenddate=$(TZ=$timezone date -d "$enddatetime" )
			
			#echo $localstartdate
        		utcstartdate=$(TZ=UTC date -d "$localstartdate" +'%Y-%m-%d %H:%M:%SZ')
        		utcenddate=$(TZ=UTC date -d "$localenddate" +'%Y-%m-%d %H:%M:%SZ')

        		echo "$(date +'%Y-%m-%d %H:%M:%S') Local : $localstartdate" 2>&1 | tee -a $log_path
        		echo "$(date +'%Y-%m-%d %H:%M:%S') UTC   : $utcstartdate" 2>&1 | tee -a $log_path
        		echo "$(date +'%Y-%m-%d %H:%M:%S') Local : $localenddate" 2>&1 | tee -a $log_path
        		echo "$(date +'%Y-%m-%d %H:%M:%S') UTC   : $utcenddate" 2>&1 | tee -a $log_path

			# Formats the date with URL encoding to label filenames

		        startdate=$(echo $utcstartdate | sed 's/ /T/g;s/:/%3A/g')
        		enddate=$(echo $utcenddate | sed 's/ /T/g;s/:/%3A/g')

        		# Checks date range for any existing datum

        		echo "$(date +'%Y-%m-%d %H:%M:%S') Checking for any data between specified date range " 2>&1 | tee -a $log_path
        		echo -n "$(date +'%Y-%m-%d %H:%M:%S') Executing python3 solnet_query.py --node=\"$node\" --sourceids=\"$sourceids\" " | tee -a $log_path
        		echo -n "--startdate=\"$startdate\" --enddate=\"$enddate\" --aggregate=\"None\" --maxoutput=\"$maxoutput\" " | tee -a $log_path
        		echo "--token=\"$token\" --secret=\"$secret\"" | tee -a $log_path

        		>data/${node}_${sourceids}_${startdate}_${enddate}_datum
			
			python3 solnet_query.py --node="$node" --sourceids="$sourceids" --startdate="$startdate" \
				--enddate="$enddate" --aggregate="None" --maxoutput="$maxoutput" --token="$token" \
				--secret="$secret" 2>&1 | tee -a data/${node}_${sourceids}_${startdate}_${enddate}_datum
							
			datum_count=$(sed '1d'  data/${node}_${sourceids}_${startdate}_${enddate}_datum | wc -l)

			# Checks for errors in solnet_query.py results and aborts if there are any

		        if [[ "$(cat data/${node}_${sourceids}_${startdate}_${enddate}_datum)" == *"Error"* ]] ; then
                		echo -n "$(date +'%Y-%m-%d %H:%M:%S') " | tee -a $log_path
                		cat data/${node}_${sourceids}_${startdate}_${enddate}_datum 2>&1 | tee -a $log_path
                		echo -n "$(date +'%Y-%m-%d %H:%M:%S') Usage: solnet-filler [--help|-h] --node|-n [NODE] --sourceid|-i " | tee -a $log_path
                		echo -n "[SOURCE ID] --timezone|-z [TIMEZONE] --startdatetime|-s [START DATETIME in \"YYYY-MM-DD HH:MM\"] " | tee -a $log_path
                		echo -n "--enddatetime|-e [END DATETIME in \"YYYY-MM-DD HH:MM\"] --latitude|-a [LATITUDE] --longitude|-o " | tee -a $log_path
                		echo -n "[LONGITUDE] --energyspike|-g [ENERGY SPIKE IN watthours] --api|-p [SOLCAST API TOKEN] " | tee -a $log_path
				echo "--token|-k [SOLNET TOKEN] --secret|-c [SOLNET SECRET]" | tee -a $log_path
        		else
				# Process of deleting data between the date range
		                if [ $datum_count -gt 0 ]; then

                	        	# Ensures format is correct
                        		formatted_localstartdate=$(date -d "$localstartdate" +'%Y-%m-%d %H:%M:%S')
                        		formatted_localenddate=$(date -d "$localenddate" +'%Y-%m-%d %H:%M:%S')

                        		# Commands that will be executed to delete data
                        		echo "$(date +'%Y-%m-%d %H:%M:%S') Datum count in gap is greater than 0. Preview and " | tee -a $log_path
                        		echo "Confirm commands below will be executed:" | tee -a $log_path
                        		echo -n "Preview: python3 solnet_expire_preview.py --node=\"$node\" " | tee -a $log_path
                        		echo -n "--sourceids=\"$sourceids\" --localstartdate=\"$formatted_localstartdate\" " | tee -a $log_path
                        		echo "--localenddate=\"$formatted_localenddate\" --token=\"$token\" --secret=\"$secret\"" | tee -a $log_path
                        		echo -n "Confirm: python3 solnet_expire_confirm.py --node=\"$node\" " | tee -a $log_path
                        		echo -n "--sourceids=\"$sourceids\" --localstartdate=\"$formatted_localstartdate\" " | tee -a $log_path
                        		echo "--localenddate=\"$formatted_localenddate\" --token=\"$token\" --secret=\"$secret\"" | tee -a $log_path
				
					# Prompt user confrimation before deleting data
                        		while true
                        		do

                                		echo -n "$(date +'%Y-%m-%d %H:%M:%S') Would you like to remove the data between" | tee -a $log_path
                                		echo "the gap now now (Y/N)?" | tee -a $log_path
                                		read continue_result < /dev/tty

                                		if [[ "${continue_result^^}" == "Y" || "${continue_result^^}" == "N" ]] ; then
                                       		 	echo "$(date +'%Y-%m-%d %H:%M:%S') Continue Result recevied $continue_result" 2>&1 | tee -a $log_path
                                        		break;
                                		fi
                        		done

					if [[ "${continue_result^^}" == "Y" ]] ; then

                               			# Preview of the number of data to be deleted
                                		echo -n "$(date +'%Y-%m-%d %H:%M:%S') Executing python3 solnet_expire_preview.py "
                                		echo -n "--node=\"$node\" --sourceids=\"$sourceids\" " | tee -a $log_path
                                		echo -n "--localstartdate=\"$formatted_localstartdate\" " | tee -a $log_path
                                		echo -n "--localenddate=\"$formatted_localenddate\" " | tee -a $log_path
                                		echo "--token=\"$token\" --secret=\"$secret\"" | tee -a $log_path

                                		result_count=$(python3 solnet_expire_preview.py --node="$node" --sourceids="$sourceids" \
                                        		--localstartdate="$formatted_localstartdate" --localenddate="$formatted_localenddate" \
                                        		--token="$token" --secret="$secret")

                                		echo "$(date +'%Y-%m-%d %H:%M:%S') COUNT RESULT = $result_count" 2>&1 | tee -a $log_path

                              			# If preview doesn't match the number of data queried between the date range then it aborts the delete process
                                		# and suggests the delete process to be done manually as there could be too many datum for the solnet query to
                                		# download
				
						if [ $result_count -ne $gap_count ] ; then
                                		        echo -n "$(date +'%Y-%m-%d %H:%M:%S') Skipping Process. Count doesn't match, " | tee -a $log_path
                                        		echo "adjust date and run manually. " | tee -a $log_path
                                		else
                                        		echo -n "$(date +'%Y-%m-%d %H:%M:%S') Count of previewed data match count of data " | tee -a $log_path
                                        		echo "between date range." 2>&1 | tee -a $log_path

                                        		# Actual delete process with 10 second delay to give user a chance to cancel process
                                        		echo -n "$(date +'%Y-%m-%d %H:%M:%S') Executing python3 solnet_expire_confirm.py " | tee -a $log_path
                                        		echo -n "--node=\"$node\" --sourceids=\"$sourceids\" " | tee -a $log_path
                                       			echo -n "--localstartdate=\"$formatted_localstartdate\" " | tee -a $log_path
                                        		echo -n "--localenddate=\"$formatted_localenddate\" --token=\"$token\"" | tee -a $log_path
                                        		echo "--secret=\"$secret\" in 10 seconds. Hit CTRL + C to Cancel" | tee -a $log_path
                                        		sleep 10

                                        		python3 solnet_expire_confirm.py --node="$node" --sourceids="$sourceids" \
                                                		--localstartdate="$formatted_localstartdate" --localenddate="$formatted_localenddate" \
                                                		--token="$token" --secret="$secret" 2>&1 | tee -a $log_path

                                        		# Command to show the progress of the delete process
                                        		echo -n "$(date +'%Y-%m-%d %H:%M:%S') Execute python3 solnet_manage_jobs.py " | tee -a $log_path
                                        		echo -n "--job=\"expire\" --action=\"list\" --token=\"$token\" " | tee -a $log_path
                                        		echo "--secret=\"$secret\" to monitor progress" | tee -a $log_path
                                		fi

                        		else
                                		echo "$(date +'%Y-%m-%d %H:%M:%S') Delete Process Aborted" 2>&1 | tee -a $log_path
                        		fi
				else
		                        echo "$(date +'%Y-%m-%d %H:%M:%S') No Data Detected. Preparing Solcast Query Data" 2>&1 | tee -a $log_path
                		fi

				# Solcast Download Process

		                # File where the python commands to download solcast data will be stored.
               			solcast_script_path="data/${node}_${sourceids}_${lat}_${long}_${startdate}_${enddate}_solcast_script.sh"

                		# File where the result of the python commands to download solcast data will be stored.
                		solcast_csv_path="data/${node}_${sourceids}_${lat}_${long}_${startdate}_${enddate}_solcast_result.csv"
                		>$solcast_script_path

                		# UTC date is used as it is  required when downloading solcast data. Date is converted to epoch to perform
                		# aritmethtic operation with the date
                		solcast_start=$utcstartdate
                		solcast_end=$utcenddate

                		solcast_start_epoch=$(date -d "$solcast_start" +%s)
                		solcast_end_epoch=$(date -d "$solcast_end" +%s)

               			# Computes the difference between the start and end dates to determine the number of seconds between the date range.
                		date_range_diff_seconds=$((solcast_end_epoch - solcast_start_epoch))

                		# This condition checks if the date range exceeds the limit of 2592000  seconds which is 30 days
                		# since there is a 30 day limit on date range per solcast download.

				if [ $date_range_diff_seconds -gt 2592000  ]; then

                        		solcast_partial_end=$(date --date "$solcast_start + 30 days" +'%Y-%m-%d %H:%M:%SZ')
                        		echo "$(date +'%Y-%m-%d %H:%M:%S') Date range exceeds 30 days, creating multiple solcast queries" 2>&1 | tee -a $log_path
                        		echo -n "python3 solcast_download.py --latitude=\"$lat\" --longitude=\"$long\" " | tee -a $solcast_script_path
                        		echo -n "--startdate=\"$solcast_start\" --enddate=\"$solcast_partial_end\" " | tee -a $solcast_script_path
                        		echo    "--token=\"$solcast_api_token\" > $solcast_csv_path" | tee -a $solcast_script_path

                        		solcast_partial_start=$(date --date "$(date -Iseconds -d "$solcast_partial_end") + 1 second" +'%Y-%m-%d %H:%M:%SZ')
                        		solcast_partial_epoch=$(date -d "$solcast_partial_start" +%s )
                        		date_range_diff_seconds=$((solcast_end_epoch - solcast_partial_epoch))

                        		while [ $date_range_diff_seconds -gt 2592000 ]
                        		do
                                		if [ $date_range_diff_seconds -gt 2592000 ]; then

                                        		solcast_partial_end=$(date --date "$solcast_partial_start + 30 days" +'%Y-%m-%d %H:%M:%SZ')
                                        		echo -n "python3 solcast_download.py --latitude=\"$lat\" --longitude=\"$long\" " | tee -a $solcast_script_path
                                        		echo -n "--startdate=\"$solcast_partial_start\" --enddate=\"$solcast_partial_end\" " | tee -a $solcast_script_path
                                        		echo    "--token=\"$solcast_api_token\" >> $solcast_csv_path" | tee -a $solcast_script_path

                                        		solcast_partial_start=$(date --date "$(date -Iseconds -d "$solcast_partial_end") + 1 second" +'%Y-%m-%d %H:%M:%SZ')
                                        		solcast_partial_epoch=$(date -d "$solcast_partial_start" +%s )
                                        		date_range_diff_seconds=$((solcast_end_epoch - solcast_partial_epoch))
                                		else
                                        		solcast_partial_start=$(date --date "$(date -Iseconds -d "$solcast_partial_end") + 1 second" +'%Y-%m-%d %H:%M:%SZ')
                                        		break
                                		fi
                        		done
					
					echo -n "python3 solcast_download.py --latitude=\"$lat\" --longitude=\"$long\" " | tee -a $solcast_script_path
		                        echo -n "--startdate=\"$solcast_partial_start\" --enddate=\"$solcast_end\" " | tee -a $solcast_script_path
                		        echo    "--token=\"$solcast_api_token\" >> $solcast_csv_path" | tee -a $solcast_script_path
                		else
                        		echo -n "python3 solcast_download.py --latitude=\"$lat\" --longitude=\"$long\" " | tee -a $solcast_script_path
                       	 		echo -n "--startdate=\"$solcast_start\" --enddate=\"$solcast_end\" " | tee -a $solcast_script_path
                        		echo    "--token=\"$solcast_api_token\" > $solcast_csv_path" | tee -a $solcast_script_path
                		fi

		                echo -n "$(date +'%Y-%m-%d %H:%M:%S') Executing /bin/bash $solcast_script_path in 10 seconds. " | tee -a $log_path
                		echo "Hit Ctrl + C to Cancel" | tee -a $log_path
                       		sleep 10
                        	/bin/bash $solcast_script_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Process Completed" | tee -a $log_path
					
				if [[ "$sourceids" == *"PYR"* ]] ; then
					runtime=$(date +"%Y%m%d_%H%M%S")
                     	   		irradiance_data_path="data/${node}_${sourceids}_${startdate}_${enddate}_PYRGAP_SolNetIMport_${runtime}.csv"
                        		a=0
                        		echo -n "$(date +'%Y-%m-%d %H:%M:%S') Calculating irradiance hours for node $node and " | tee -a $log_path
                        		echo "source $sid from $startdate to $enddate" | tee -a $log_path
                        		while IFS=, read periodend periodstart period ghi
                        		do
                                		periodstart_formatted=$(echo $periodstart | sed "s/T/ /g" | sed "s/Z//g")

                                		# First condition is used to identify the first record where accumulating irradiance hours is just
                                		# equal to the instantaneuous irradiance
                                		if [[ $a = 0 ]] ; then
                                        		echo "node,source,date,irradiance,irradianceHours" > $irradiance_data_path
                                        		echo "$node,$sid,$periodstart_formatted,$ghi,$ghi" >> $irradiance_data_path
                                        		ghi_prev=$ghi
                                        		a=1
                                		else
                                        		# Adds a 12th of an irradiance hour based on the instantaneous irradiance, in this case  ghi.
                                        		# Thatâ€™s because these are 5-min resolution data samples, and there are 12 of them in one
                                        		# 60-minute hour.
                                        		ghi_5min=$(echo "scale=8; $ghi/12" | bc )

                                        		if [[ $ghi -lt 12 && $ghi -gt 0  ]] ; then
                                               			# Fixes missing leading 0 when the value is a decimal and less than 1
                                                		ghi_new=$(echo "$ghi_prev + $ghi_5min" | bc | awk '{printf "%.8f", $0}' )
                                        		else
                                                		ghi_new=$(echo "$ghi_prev + $ghi_5min" | bc  )
                                        		fi
                                        		ghi_prev=$ghi_new
                                        		echo "$node,$sid,$periodstart_formatted,$ghi,$ghi_new" >> $irradiance_data_path
                                		fi
					done < $solcast_csv_path
					
					file_to_import=$irradiance_data_path

				elif [[ "$sourceids" == *"GEN"* ]] ; then
					a=0
        			        previous_watthours=0
	                		total_energy=$energyspike
                			electrical_energy_data_path="data/${node}_${sourceids}_EEGAP_SolNetIMport_${runtime}.csv"
                			runtime=$(date +"%Y%m%d_%H%M%S")

                			# Calculate total irradiance generated from solcast download
                			ghitotal=$( cat $solcast_csv_path | awk -F"," '{sum+=($4)} END {print sum}' )

                			echo "$(date +'%Y-%m-%d %H:%M:%S') Total Irrandiace Calculated: $ghitotal" | tee -a $log_path
                			echo "$(date +'%Y-%m-%d %H:%M:%S') Total Enery Spike in watthours: $energyspike" | tee -a $log_path

                			echo "$(date +'%Y-%m-%d %H:%M:%S') Calculating Backfill Data Driven by Irradiance Data" | tee -a $log_path
                			echo "NodeID,SourceID,Date,watts,wattHours" > $electrical_energy_data_path
                
					while IFS=, read endperiod startperiod period irr
                			do
                        			formatted_startperiod=$(echo $startperiod | sed "s/T/ /g ; s/Z//g")
                        			watts=$(echo "scale=8 ; ( $total_energy * ($irr / $ghitotal) * 12 ) " | bc )
                        			watthours=$(echo "scale=8 ; $previous_watthours + ($watts / 12)" | bc )
                        			previous_watthours=$watthours
                        			echo "$node,$sid,$formatted_startperiod,$watts,$watthours" >> $electrical_energy_data_path
                			done < $solcast_csv_path

					file_to_import=$electrical_energy_data_path
        			else
                			echo "$(date +'%Y-%m-%d %H:%M:%S') Unable to determine type of datum from source ID"
					exit 1
				fi
				
				echo "$(date +'%Y-%m-%d %H:%M:%S') Displaying parts of output file $file_to_import" | tee -a $log_path
	                        head -n 5 $file_to_import | tee -a $log_path
        	                echo "....." | tee -a $log_path
                	        tail -n 5 $file_to_import | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Compressing output file $file_to_import" | tee -a $log_path
                        	dos2unix $file_to_import
                        	sleep 1
                        	xz -k $file_to_import
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Process completed" | tee -a $log_path

				###########################################################################################
	                        echo "$(date +'%Y-%m-%d %H:%M:%S') Determining Stitch Parameters" 2>&1 | tee -a $log_path
	
        	                # Creating a data sample window that is 1 hour before the startdate to get the final reading at the start of the gap
                	        startdate_1hour_before=$(date --date "$(date -Iseconds -d "$utcstartdate") - 1 hour" \
                        	        +'%Y-%m-%d %H:%M:%SZ' | sed 's/ /T/g;s/:/%3A/g')
                        	startdate_5sec_before=$(date --date "$(date -Iseconds -d "$utcstartdate") - 5 seconds" \
                                	+'%Y-%m-%d %H:%M:%SZ' | sed 's/ /T/g;s/:/%3A/g')
                      		echo -n "$(date +'%Y-%m-%d %H:%M:%S') Executing python3 solnet_query.py --node=\"$node\" " | tee -a $log_path
                        	echo -n "--sourceids=\"$sourceids\" --startdate=\"$startdate_1hour_before\" " | tee -a $log_path
                        	echo -n "--enddate=\"$startdate_5sec_before\" --aggregate=\"None\" " | tee -a $log_path
                        	echo -n "--maxoutput=\"$maxoutput\" --token=\"$token\" " | tee -a $log_path
                        	echo "--secret=\"$secret\" to determine SN EVENT 1" | tee -a $log_path

                        	# Filename where possible boundary readings at the start of the gap is stored
                        	sne1_datum="data/${node}_${sourceids}_${startdate_1hour_before}_${startdate_5sec_before}_datum"
                        	python3 solnet_query.py --node="$node" --sourceids="$sourceids" --startdate="$startdate_1hour_before" \
                                	--enddate="$startdate_5sec_before" --aggregate="None" --maxoutput="$maxoutput" --token="$token" \
                                	--secret="$secret" > $sne1_datum

				sed -i '1d' $sne1_datum

        	                # If there is no datum before the start of the gap, final reading is 0 and start and end time for event 1 is 5 seconds before the start date of the gap
	                        if [ -z "$(cat $sne1_datum)" ] ; then
                	                snevent1_start_end_datetime=$(date --date "$(date -Iseconds -d "$localstartdate") - 5 seconds" \
                        	                +'%b %d, %Y %H:%M:%S')
                               		sne1_final_reading=0
                        	# If there is datum before the start of the gap, final reading is the last datum entry and start and end time for event 1 is 5 seconds after the last datum entry
                        	else
                                	sne1_utcdatetime=$(cat $sne1_datum | tail -n 1 | awk -F ',' '{print $1}' )
					sne1_startlocaldate=$(cat $sne1_datum | tail -n 1 | awk -F ',' '{print $2}' )
                                	sne1_startlocaltime=$(cat $sne1_datum | tail -n 1 | awk -F ',' '{print $3}' )
                                        sne1_utc_halfsec=$(echo $sne1_utcdatetime | awk -F ':' '{print $NF}' | sed 's/Z//g')

                                	if [[ "$sourceids" == *"PYR"* ]]; then
						sne1_final_reading=$(cat $sne1_datum | tail -n 1| awk -F ',' '{print $NF}')
                                	elif [[ "$sourceids" == *"GEN"* ]]; then
						sne1_final_reading=$(cat $sne1_datum | tail -n 1| awk -F ',' '{print $(NF-2)}')
					else
						echo "$(date +'%Y-%m-%d %H:%M:%S') Unable to determine type of datum from source ID" | tee -a $log_path
						sne1_final_reading="Error Unable to determine type of datum from source ID"
					fi
					snevent1_start_end_datetime=$(date --date "$(date -Iseconds -d "$sne1_startlocaldate $sne1_startlocaltime:$sne1_utc_halfsec") \
						+ 5 seconds" +'%b %d, %Y %H:%M:%S')
                        	fi
	
				# Creating a data sample window that is 1 hour after the enddate to get the start reading at the end of the gap
                        	startdate_5sec_after=$(date --date "$(date -Iseconds -d "$utcenddate") + 5 seconds" +'%Y-%m-%d %H:%M:%SZ' | \
                                	sed 's/ /T/g;s/:/%3A/g')
                        	startdate_1hour_after=$(date --date "$(date -Iseconds -d "$utcenddate") + 1 hour" +'%Y-%m-%d %H:%M:%SZ' | \
                               		sed 's/ /T/g;s/:/%3A/g')

                        	echo -n "$(date +'%Y-%m-%d %H:%M:%S') Executing python3 solnet_query.py --node=\"$node\" " | tee -a $log_path
                       		echo -n "--sourceids=\"$sourceids\" --startdate=\"$startdate_5sec_after\" " | tee -a $log_path
                        	echo -n "--enddate=\"$startdate_1hour_after\" --aggregate=\"None\" " | tee -a $log_path
                        	echo -n "--maxoutput=\"$maxoutput\" --token=\"$token\" " | tee -a $log_path
                        	echo "--secret=\"$secret\" to determine SN EVENT 2" | tee -a $log_path

                        	# Filename where possible boundary readings at the end of the gap is stored
                        	sne2_datum="data/${node}_${sourceids}_${startdate_5sec_after}_${startdate_1hour_after}_datum"
                        	python3 solnet_query.py --node="$node" --sourceids="$sourceids" --startdate="$startdate_5sec_after" \
					--enddate="$startdate_1hour_after" --aggregate="None" --maxoutput="$maxoutput" \
					--token="$token" --secret="$secret" > $sne2_datum

                        	sed -i '1d' $sne2_datum

                        	# If there is no datum after the end of the gap, final reading is 0 and the start and end time for event 2 is 5 seconds after the end date of the gap
                        	if [ -z "$(cat $sne2_datum)" ] ; then
                                	snevent2_start_end_datetime=$(date --date "$(date -Iseconds -d "$localenddate") + 5 seconds" \
                                        	+'%b %d, %Y %H:%M:%S')
                                	sne2_start_reading=0
                        	# If there is datum after the end of the gap, final reading is the first datum entry and the start and end time 
				# for event 2 is 5 seconds before the first datum entry
                        	else
                                	sne2_utcdatetime=$(cat $sne2_datum | head -n 1 | awk -F ',' '{print $1}' )
					sne2_endlocaldate=$(cat $sne2_datum | head -n 1 | awk -F ',' '{print $2}' )
                                	sne2_endlocaltime=$(cat $sne2_datum | head -n 1 | awk -F ',' '{print $3}' )
                                	sne2_utc_halfsec=$(echo $sne2_utcdatetime | awk -F ':' '{print $NF}' | sed 's/Z//g')
					
					if [[ "$sourceids" == *"PYR"* ]]; then
                                         	sne2_start_reading=$(cat $sne2_datum | head -n 1| awk -F ',' '{print $NF}')
                                        elif [[ "$sourceids" == *"GEN"* ]]; then
						sne2_start_reading=$(cat $sne2_datum | head -n 1| awk -F ',' '{print $(NF-2)}')
                                        else
                                                echo "$(date +'%Y-%m-%d %H:%M:%S') Unable to determine type of datum from source ID" | tee -a $log_path
                                                sne2_start_reading="Error Unable to determine type of datum from source ID"
                                        fi
                                	
					snevent2_start_end_datetime=$(date --date "$(date -Iseconds -d \
						"$sne2_endlocaldate $sne2_endlocaltime:$sne2_utc_halfsec") - 5 seconds" +'%b %d, %Y %H:%M:%S')
                        	fi

                        	# Get start reading of event 1
                        	sne1_start_reading=$(head -n 2 $file_to_import | tail -n 1 | awk -F ',' '{print $NF}')

                        	# Get final reading of event 2
                        	sne2_final_reading=$(tail -n 1 $file_to_import | awk -F ',' '{print $NF}')
				
                        	# Summary of Solnet Event Parameters
                       		echo "$(date +'%Y-%m-%d %H:%M:%S') Solar Network Event 1" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Cause: Discontinuity due to Gap" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Description: Start Border " | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Node ID: $node" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Source ID: $sid" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Start datetime: $snevent1_start_end_datetime" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') End datetime: $snevent1_start_end_datetime" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Final reading: $sne1_final_reading" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Start Reading: $sne1_start_reading" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Solar Network Event 2" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Cause: Discontinuity due to Gap" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Description: End Border " | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Node ID: $node" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Source ID: $sid" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Start datetime: $snevent2_start_end_datetime" |  tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') End datetime: $snevent2_start_end_datetime" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Final reading: $sne2_final_reading" | tee -a $log_path
                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Start Reading: $sne2_start_reading" | tee -a $log_path


				###################################################################################
        	                echo "$(date +'%Y-%m-%d %H:%M:%S') Creating staged data" | tee -a $log_path
	                        echo "$(date +'%Y-%m-%d %H:%M:%S') Checking size of file" | tee -a $log_path
                	        filesizebytes=$(ls -l $file_to_import | awk '{print $5}')
                        	filsesizemb=$(($filesizebytes/1048576))

                        	echo "$(date +'%Y-%m-%d %H:%M:%S') Size of file: $filsesizemb" | tee -a $log_path

                        	if [ $filsesizemb -lt 20 ] ; then
                                	compress="disabled"
                       		else
					file_to_import="${file_to_import}.xz"
                                	compress="enabled"
                        	fi

                        	echo -n "$(date +'%Y-%m-%d %H:%M:%S') Executing python3 solnet_import.py --node=\"$node\" " | tee -a $log_path
                        	echo -n "--sourceids=\"$sourceids\" --timezone=\"UTC\" --compression=\"$compress\" " | tee -a $log_path
                        	echo "--filepath=\"$file_to_import\" --token=\"$token\" --secret=\"$secret\" in 10 seconds. Hit Ctrl + C to Cancel" | tee -a $log_path
                                
				sleep 10
                                jobid=$(python3 solnet_import.py --node="$node" --sourceids="$sourceids" --timezone="UTC" --compression="$compress" \
					--filepath="$file_to_import" --token="$token" --secret="$secret")
                                
				echo -n "$(date +'%Y-%m-%d %H:%M:%S') Executing python3 solnet_manage_jobs.py " | tee -a $log_path
                                echo -n "--job=\"import\" --action=\"preview\" --token=\"$token\" " | tee -a $log_path
                                echo "--secret=\"$secret\" --jobid=\"$jobid\" to preview imported data" | tee -a $log_path
                        
				python3 solnet_manage_jobs.py --job="import" --action="preview" --token="$token" \
                                --secret="$secret" --jobid="$jobid" 2>&1 | tee -a $log_path

                                echo -n "$(date +'%Y-%m-%d %H:%M:%S') To apply staged data, python3 " | tee -a $log_path
                                echo -n "solnet_manage_jobs.py --job=\"import\" --action=\"confirm\" " | tee -a $log_path
                                echo "--token=\"$token\" --secret=\"$secret\" --jobid=\"$jobid\" will be executed" | tee -a $log_path

                                while true
                                do
                                	echo -n "$(date +'%Y-%m-%d %H:%M:%S') Would You Like To Proceed To Apply Staged Data [Y/N]: "
                                	read confirm_result < /dev/tty

                                	if [[ "${confirm_result^^}" == "Y" || "${confirm_result^^}" == "N" ]] ; then
                                		echo "$(date +'%Y-%m-%d %H:%M:%S') Confirm Result recevied $confirm_result" | tee -a $log_path
                                		break;
                                	fi
                                done
                        
				if [[ "${confirm_result^^}" == "Y" ]] ; then

					if [ $datum_count -gt 0 ]; then

						echo "$(date +'%Y-%m-%d %H:%M:%S') Checking if expire process has completed." | tee -a $log_path
						
						result_count=$(python3 solnet_expire_preview.py --node="$node" --sourceids="$sourceids" \
                                                --localstartdate="$formatted_localstartdate" --localenddate="$formatted_localenddate" \
                                                --token="$token" --secret="$secret")

                                               	if [ $result_count -eq 0 ] ; then
                                			
							echo "$(date +'%Y-%m-%d %H:%M:%S') Expire result count: $result_count. Process completed." | tee -a $log_path

							echo -n "$(date +'%Y-%m-%d %H:%M:%S') Executing python3 " | tee -a $log_path
                                			echo -n "solnet_manage_jobs.py --job=\"import\" --action=\"confirm\" " | tee -a $log_path
                                			echo -n "--token=\"$token\" --secret=\"$secret\" --jobid=\"$jobid\" " | tee -a $log_path
                                			echo    "in 10 seconds. Hit CTRL+C to cancel" | tee -a $log_path
                                			sleep 10
				
							python3 solnet_manage_jobs.py --job="import" --action="confirm" --token="$token"\
							       	--secret="$secret" --jobid="$jobid" 2>&1 | tee -a $log_path
						
							echo -n "$(date +'%Y-%m-%d %H:%M:%S') Execute python3 solnet_manage_jobs.py " | tee -a $log_path
        	                                        echo -n "--job=\"import\" --action=\"list\" --token=\"$token\" " | tee -a $log_path
	                                                echo    "--secret=\"$secret\" to view import progress" | tee -a $log_path

						else
							echo "$(date +'%Y-%m-%d %H:%M:%S') Process aborted. Expire process not completed. Run manually." | tee -a $log_path
						fi
					else
						 echo -n "$(date +'%Y-%m-%d %H:%M:%S') Executing python3 " | tee -a $log_path
                                                 echo -n "solnet_manage_jobs.py --job=\"import\" --action=\"confirm\" " | tee -a $log_path
                                                 echo -n "--token=\"$token\" --secret=\"$secret\" --jobid=\"$jobid\" " | tee -a $log_path
                                                 echo    "in 10 seconds. Hit CTRL+C to cancel" | tee -a $log_path
                                                 sleep 10

                                                 python3 solnet_manage_jobs.py --job="import" --action="confirm" --token="$token"\
							 --secret="$secret" --jobid="$jobid" 2>&1 | tee -a $log_path
						 
						 echo -n "$(date +'%Y-%m-%d %H:%M:%S') Execute python3 solnet_manage_jobs.py " | tee -a $log_path
                                                 echo -n "--job=\"import\" --action=\"list\" --token=\"$token\" " | tee -a $log_path
                                                 echo    "--secret=\"$secret\" to view import progress" | tee -a $log_path

					fi
				else
                                	echo -n "$(date +'%Y-%m-%d %H:%M:%S') Import Process Aborted. " | tee -a $log_path
                                	echo -n "Deleting Staged Data. Executing python3 " | tee -a $log_path
                                	echo -n "solnet_manage_jobs.py --job=\"import\" --action=\"delete\" " | tee -a $log_path
                                	echo -n "--token=\"$token\" --secret=\"$secret\" " | tee -a $log_path
                                	echo    "--jobid=\"$jobid\" in 10 seconds. Hit CTRL+C to cancel" | tee -a $log_path
                                	sleep 10
                                	python3 solnet_manage_jobs.py --job="import" --action="delete" --token="$token" --secret="$secret" --jobid="$jobid" 2>&1 | tee -a $log_path
                                fi
			fi
		fi
	else
		echo "$(date +'%Y-%m-%d %H:%M:%S') Unable to determine type of datum (GEN/PYR) from source ID provided"
		exit 1
	fi
	
fi

