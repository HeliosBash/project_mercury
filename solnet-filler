#!/bin/bash

# Logging function
log() {
    echo "$(date +'%Y-%m-%d %H:%M:%S') $*" | tee -a "$log_path"
}

# Confirmation function
confirm_action() {
    local prompt="$1"
    while true; do
        echo -n "$(date +'%Y-%m-%d %H:%M:%S') $prompt [Y/N]: "
        read reply < /dev/tty
        if [[ "${reply^^}" == "Y" || "${reply^^}" == "N" ]] ; then
            log "User response: $reply"
            echo "${reply^^}"
            return
        fi
    done
}

while [ $# -gt 0 ] ; do
        case "$1" in
                --node*|-n*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        node="${1#*=}"
                        ;;
                --sourceid*|-i*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        sid="${1#*=}"
                        ;;
                --timezone*|-z*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        timezone="${1#*=}"
                        ;;
                --startdatetime*|-s*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        startdatetime="${1#*=}"
                        ;;
                --enddatetime*|-e*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        enddatetime="${1#*=}"
                        ;;
                --latitude*|-a*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        lat="${1#*=}"
                        ;;
                --longitude*|-o*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        long="${1#*=}"
                        ;;
                --energyspike*|-g*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        energyspike="${1#*=}"
                        ;;
                --api*|-p*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        solcast_api_token="${1#*=}"
                        ;;
                --token*|-k*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        token="${1#*=}"
                        ;;
                --secret*|-c*)
                        if [[ "$1" != *=* ]]; then shift; fi
                        secret="${1#*=}"
                        ;;
                --help|-h)
                        echo -n "Usage: solnet-filler [--help|-h] --node|-n [NODE] --sourceid|-i [SOURCE ID] --timezone|-z [TIMEZONE]"
                        echo -n "--startdate|-s [STARTDATETIME in \"YYYY-MM-DD HH:MM\"] --enddatetime|-e [ENDDATETIME "
                        echo -n "in \"YYYY-MM-DD HH:MM\"] --latitude|-a [LATITUDE] --longitude|-o [LONGITUDE] "
                        echo -n "--energyspike|-g [ENERGY SPIKE IN watthours] --api|-p [SOLCAST API TOKEN] --token|-k "
                        echo "[SOLNET TOKEN] --secret|-c [SOLNET SECRET]"
                        exit 0
                        ;;
                *)
                        >&2 echo -n "Error: The following arguments are required --node --sourceid --timezone --startdatetime "
                        echo "--enddatetime --latitude --longitude --energyspike --api --token --secret. For PYR Fills, set energyspike to 0"
                        exit 1
                        ;;
        esac
        shift
done

if [[ -z "$node" || -z "$sid" || -z "$timezone" || -z "$startdatetime" || -z "$enddatetime" || -z "$lat" || -z "$long" || -z "$energyspike" \
        || -z "$solcast_api_token" || -z "$token" || -z "$secret" ]] ; then

        echo -n "Error: The following arguments are required --node --sourceid --timezone --startdatetime --enddatetime --latitude "
        echo "--longitude --energyspike --api --token --secret. For PYR Fills, set energyspike to 0"

else
        sourceids=$(echo $sid | sed "s/\//%2F/g")
        runtime=$(date +"%Y%m%d_%H%M%S")
        log_path="data/solnet-filler-${runtime}.log"
        maxoutput=1000000


        if [[ "$sourceids" == *"GEN"* ]] || [[ "$sourceids" == *"PYR"* ]] || [[ "$sourceids" == *"CON"* ]]; then
                if [[ "$sourceids" == *"GEN"* ]] && [[ "$energyspike" -eq 0 ]] ; then
                        echo "$(date +'%Y-%m-%d %H:%M:%S') For GEN Fills, energyspike should be greater than 0"
                else
                        log "Executed: /bin/bash solnet-filler --node $node --sourceid $sid --timezone $timezone --startdatetime $startdatetime --enddatetime $enddatetime --latitude $lat --longitude $long --energyspike $energyspike --api $solcast_api_token --token $token --secret $secret"

                        # Check timezone format if its valid

                        check_timezone=$(awk '/^Z/ { print $2 }; /^L/ { print $timezone }' /usr/share/zoneinfo/tzdata.zi | grep -w $timezone)

                        while [ -z "$check_timezone" ]
                        do
                                echo -n "$(date +'%Y-%m-%d %H:%M:%S') Not a valid timezone. Enter timezone:  "
                                read timezone < /dev/tty
                                check_timezone=$(awk '/^Z/ { print $2 }; /^L/ { print $timezone }' /usr/share/zoneinfo/tzdata.zi | grep -w $timezone)
                        done

                        # Sets the entered date to local and converts it to utc

                        #echo $startdatetime
                        localstartdate=$(TZ=$timezone date -d "$startdatetime" )
                        localenddate=$(TZ=$timezone date -d "$enddatetime" )

                        #echo $localstartdate
                        utcstartdate=$(TZ=UTC date -d "$localstartdate" +'%Y-%m-%d %H:%M:%SZ')
                        utcenddate=$(TZ=UTC date -d "$localenddate" +'%Y-%m-%d %H:%M:%SZ')

                        log "Local : $localstartdate"
                        log "UTC   : $utcstartdate"
                        log "Local : $localenddate"
                        log "UTC   : $utcenddate"

                        # Formats the date with URL encoding to label filenames

                        startdate=$(echo $utcstartdate | sed 's/ /T/g;s/:/%3A/g')
                        enddate=$(echo $utcenddate | sed 's/ /T/g;s/:/%3A/g')

                        # Checks date range for any existing datum

                        log "Checking for any data between specified date range"
                        log "Executing python3 solnet_query.py --action=\"utc\" --node=\"$node\" --sourceids=\"$sourceids\" --startdate=\"$startdate\" --enddate=\"$enddate\" --aggregate=\"None\" --maxoutput=\"$maxoutput\" --token=\"$token\" --secret=\"$secret\""

                        >data/${node}_${sourceids}_${startdate}_${enddate}_datum

                        python3 solnet_query.py --action="utc" --node="$node" --sourceids="$sourceids" --startdate="$startdate" \
                                --enddate="$enddate" --aggregate="None" --maxoutput="$maxoutput" --token="$token" \
                                --secret="$secret" 2>&1 | tee -a data/${node}_${sourceids}_${startdate}_${enddate}_datum

                        datum_count=$(sed '1d'  data/${node}_${sourceids}_${startdate}_${enddate}_datum | wc -l)

                        # Checks for errors in solnet_query.py results and aborts if there are any

                        if [[ "$(cat data/${node}_${sourceids}_${startdate}_${enddate}_datum)" == *"Error"* ]] ; then
                                log "$(cat data/${node}_${sourceids}_${startdate}_${enddate}_datum)"
                                log "Usage: solnet-filler [--help|-h] --node|-n [NODE] --sourceid|-i [SOURCE ID] --timezone|-z [TIMEZONE] --startdatetime|-s [START DATETIME in \"YYYY-MM-DD HH:MM\"] --enddatetime|-e [END DATETIME in \"YYYY-MM-DD HH:MM\"] --latitude|-a [LATITUDE] --longitude|-o [LONGITUDE] --energyspike|-g [ENERGY SPIKE IN watthours] --api|-p [SOLCAST API TOKEN] --token|-k [SOLNET TOKEN] --secret|-c [SOLNET SECRET]"
                        else
                                # Process of deleting data between the date range
                                if [ $datum_count -gt 0 ]; then

                                        # Ensures format is correct
                                        formatted_localstartdate=$(date -d "$localstartdate" +'%Y-%m-%d %H:%M:%S')
                                        formatted_localenddate=$(date -d "$localenddate" +'%Y-%m-%d %H:%M:%S')

                                        # Commands that will be executed to delete data
                                        log "Datum count in gap is greater than 0. Preview and Confirm commands below will be executed:"
                                        log "Preview: python3 solnet_expire.py --action=\"preview\" --node=\"$node\" --sourceids=\"$sourceids\" --localstartdate=\"$formatted_localstartdate\" --localenddate=\"$formatted_localenddate\" --token=\"$token\" --secret=\"$secret\""
                                        log "Confirm: python3 solnet_expire.py --action=\"confirm\" --node=\"$node\" --sourceids=\"$sourceids\" --localstartdate=\"$formatted_localstartdate\" --localenddate=\"$formatted_localenddate\" --token=\"$token\" --secret=\"$secret\""

                                        # Prompt user confrimation before deleting data
					continue_result=$(confirm_action "Would you like to remove the data between the gap now")

                                        if [[ "$continue_result" == "Y" ]] ; then

                                                # Preview of the number of data to be deleted
                                                log "Executing python3 solnet_expire.py --action=\"preview\" --node=\"$node\" --sourceids=\"$sourceids\" --localstartdate=\"$formatted_localstartdate\" --localenddate=\"$formatted_localenddate\" --token=\"$token\" --secret=\"$secret\""

                                                result_count=$(python3 solnet_expire.py --action="preview" --node="$node" --sourceids="$sourceids" \
                                                        --localstartdate="$formatted_localstartdate" --localenddate="$formatted_localenddate" \
                                                        --token="$token" --secret="$secret")

                                                log "COUNT RESULT = $result_count"

                                                # If preview doesn't match the number of data queried between the date range then it aborts the delete process
                                                # and suggests the delete process to be done manually as there could be too many datum for the solnet query to
                                                # download

                                                if [ $result_count -ne $datum_count ] ; then
                                                        log "Skipping Process. Count doesn't match, adjust date and run manually."
                                                else
                                                        log "Count of previewed data match count of data between date range."

                                                        # Actual delete process with 10 second delay to give user a chance to cancel process
                                                        log "Executing python3 solnet_expire.py --action=\"confirm\" --node=\"$node\" --sourceids=\"$sourceids\" --localstartdate=\"$formatted_localstartdate\" --localenddate=\"$formatted_localenddate\" --token=\"$token\" --secret=\"$secret\" in 10 seconds. Hit CTRL + C to Cancel"
                                                        sleep 10

                                                        python3 solnet_expire.py --action="confirm" --node="$node" --sourceids="$sourceids" \
                                                                --localstartdate="$formatted_localstartdate" --localenddate="$formatted_localenddate" \
                                                                --token="$token" --secret="$secret" 2>&1 | tee -a $log_path

                                                        # Command to show the progress of the delete process
                                                        log "Execute python3 solnet_manage_jobs.py --job=\"expire\" --action=\"list\" --token=\"$token\" --secret=\"$secret\" to monitor progress"
                                                fi

                                        else
                                                log "Delete Process Aborted"
                                        fi
                                else
                                        log "No Data Detected. Preparing Solcast Query Data"
                                fi

                                # Solcast Download Process

                                # File where the python commands to download solcast data will be stored.
                                solcast_script_path="data/${node}_${sourceids}_${lat}_${long}_${startdate}_${enddate}_solcast_script.sh"

                                # File where the result of the python commands to download solcast data will be stored.
                                solcast_csv_path="data/${node}_${sourceids}_${lat}_${long}_${startdate}_${enddate}_solcast_result.csv"
                                >$solcast_script_path

                                # UTC date is used as it is  required when downloading solcast data. Date is converted to epoch to perform
                                # aritmethtic operation with the date
                                solcast_start=$utcstartdate
                                solcast_end=$utcenddate

                                solcast_start_epoch=$(date -d "$solcast_start" +%s)
                                solcast_end_epoch=$(date -d "$solcast_end" +%s)

                                # Computes the difference between the start and end dates to determine the number of seconds between the date range.
                                date_range_diff_seconds=$((solcast_end_epoch - solcast_start_epoch))

                                # This condition checks if the date range exceeds the limit of 2592000  seconds which is 30 days
                                # since there is a 30 day limit on date range per solcast download.

                                if [ $date_range_diff_seconds -gt 2592000  ]; then

                                        solcast_partial_end=$(TZ=UTC date --date "$solcast_start + 30 days" +'%Y-%m-%d %H:%M:%SZ')
                                        log "Date range exceeds 30 days, creating multiple solcast queries"
                                        echo "python3 solcast_download.py --latitude=\"$lat\" --longitude=\"$long\" --startdate=\"$solcast_start\" --enddate=\"$solcast_partial_end\" --token=\"$solcast_api_token\" > $solcast_csv_path" | tee -a $solcast_script_path

                                        solcast_partial_start=$(TZ=UTC date --date "$(date -Iseconds -d "$solcast_partial_end") + 1 second" +'%Y-%m-%d %H:%M:%SZ')
                                        solcast_partial_epoch=$(date -d "$solcast_partial_start" +%s )
                                        date_range_diff_seconds=$((solcast_end_epoch - solcast_partial_epoch))

                                        while [ $date_range_diff_seconds -gt 2592000 ]
                                        do
                                                if [ $date_range_diff_seconds -gt 2592000 ]; then

                                                        solcast_partial_end=$(TZ=UTC date --date "$solcast_partial_start + 30 days" +'%Y-%m-%d %H:%M:%SZ')
                                                        echo "python3 solcast_download.py --latitude=\"$lat\" --longitude=\"$long\" --startdate=\"$solcast_partial_start\" --enddate=\"$solcast_partial_end\" --token=\"$solcast_api_token\" >> $solcast_csv_path" | tee -a $solcast_script_path

                                                        solcast_partial_start=$(TZ=UTC date --date "$(date -Iseconds -d "$solcast_partial_end") + 1 second" +'%Y-%m-%d %H:%M:%SZ')
                                                        solcast_partial_epoch=$(date -d "$solcast_partial_start" +%s )
                                                        date_range_diff_seconds=$((solcast_end_epoch - solcast_partial_epoch))
                                                else
                                                        solcast_partial_start=$(TZ=UTC date --date "$(date -Iseconds -d "$solcast_partial_end") + 1 second" +'%Y-%m-%d %H:%M:%SZ')
                                                        break
                                                fi
                                        done

                                        echo "python3 solcast_download.py --latitude=\"$lat\" --longitude=\"$long\" --startdate=\"$solcast_partial_start\" --enddate=\"$solcast_end\" --token=\"$solcast_api_token\" >> $solcast_csv_path" | tee -a $solcast_script_path
                                else
                                        echo "python3 solcast_download.py --latitude=\"$lat\" --longitude=\"$long\" --startdate=\"$solcast_start\" --enddate=\"$solcast_end\" --token=\"$solcast_api_token\" > $solcast_csv_path" | tee -a $solcast_script_path
                                fi

                                log "Executing /bin/bash $solcast_script_path in 10 seconds. Hit Ctrl + C to Cancel"
                                sleep 10
                                /bin/bash $solcast_script_path
                                log "Process Completed"

                                if [[ "$sourceids" == *"PYR"* ]] ; then
                                        runtime=$(date +"%Y%m%d_%H%M%S")
                                        irradiance_data_path="data/${node}_${sourceids}_${startdate}_${enddate}_PYRGAP_SolNetIMport_${runtime}.csv"

                                        log "Executing python3 calculate_irradiancehours.py --solcast_csv_path=\"$solcast_csv_path\" --irradiance_data_path=\"$irradiance_data_path\" --node=\"$node\" --sid=\"$sid\" in 10 seconds"

                                        sleep 5

                                        python3 calculate_irradiancehours.py --solcast_csv_path="$solcast_csv_path" --irradiance_data_path="$irradiance_data_path" \
                                                --node="$node" --sid="$sid"


                                        file_to_import=$irradiance_data_path

                                elif [[ "$sourceids" == *"GEN"* ]] || [[ "$sourceids" == *"CON"* ]] ; then

                                        electrical_energy_data_path="data/${node}_${sourceids}_EEGAP_SolNetIMport_${runtime}.csv"
                                        runtime=$(date +"%Y%m%d_%H%M%S")

                                        log "Executing python3 calculate_watthours.py --solcast_csv_path=\"$solcast_csv_path\" --energyspike=$energyspike --node=\"$node\" --sourceids=\"$sid\" --output=\"$electrical_energy_data_path\" in 10 seconds"

                                        sleep 10

                                        python3 calculate_watthours.py --solcast_csv_path="$solcast_csv_path" --energyspike=$energyspike --node="$node" \
                                                --sourceids="$sid" --output="$electrical_energy_data_path"

                                        file_to_import=$electrical_energy_data_path
                                else
                                        log "Unable to determine type of datum from source ID"
                                        exit 1
                                fi

                                log "Displaying parts of output file $file_to_import"
                                head -n 5 $file_to_import | tee -a $log_path
                                echo "....." | tee -a $log_path
                                tail -n 5 $file_to_import | tee -a $log_path
                                log "Compressing output file $file_to_import"
                                dos2unix "$file_to_import"
                                sleep 1
                                xz -k $file_to_import
                                log "Process completed"

                                ###########################################################################################
                                log "Determining Stitch Parameters"

                                # Creating a data sample window that is 1 hour before the startdate to get the final reading at the start of the gap
                                startdate_1hour_before=$(TZ=UTC date --date "$(TZ=UTC date -Iseconds -d "$utcstartdate") - 1 hour" \
                                        +'%Y-%m-%d %H:%M:%SZ' | sed 's/ /T/g;s/:/%3A/g')
                                startdate_1sec_before=$(TZ=UTC date --date "$(TZ=UTC date -Iseconds -d "$utcstartdate") - 1 second" \
                                        +'%Y-%m-%d %H:%M:%SZ' | sed 's/ /T/g;s/:/%3A/g')
                                log "Executing python3 solnet_query.py --action=\"utc\" --node=\"$node\" --sourceids=\"$sourceids\" --startdate=\"$startdate_1hour_before\" --enddate=\"$startdate_1sec_before\" --aggregate=\"None\" --maxoutput=\"$maxoutput\" --token=\"$token\" --secret=\"$secret\" to determine SN EVENT 1"

                                # Filename where possible boundary readings at the start of the gap is stored
                                sne1_datum="data/${node}_${sourceids}_${startdate_1hour_before}_${startdate_1sec_before}_datum"
                                python3 solnet_query.py --action="utc" --node="$node" --sourceids="$sourceids" --startdate="$startdate_1hour_before" \
                                        --enddate="$startdate_1sec_before" --aggregate="None" --maxoutput="$maxoutput" --token="$token" \
                                        --secret="$secret" > $sne1_datum

                                sed -i '1d' $sne1_datum
                                log "Showing data at start border"
                                tail -n 5 $sne1_datum | tee -a $log_path


                                # If there is no datum before the start of the gap, final reading is 0 and start and end time for event 1 is 5 seconds before the start date of the gap
                                if [ -z "$(cat $sne1_datum)" ] ; then
                                        snevent1_start_end_datetime=$(date --date "$(date -Iseconds -d "$localstartdate") - 5 seconds" \
                                                +'%b %d, %Y %H:%M:%S')
                                        snevent1_utc_start_end_datetime=$(TZ=UTC date --date "$(date -Iseconds -d "$utcstartdate") - 5 seconds" \
                                                +'%Y-%m-%d %H:%M:%SZ')
                                        sne1_final_reading=0
                                # If there is datum before the start of the gap, final reading is the last datum entry and start and end time for event 1 is 5 seconds after the last datum entry
                                else
                                        sne1_utcdatetime=$(cat $sne1_datum | tail -n 1 | awk -F ',' '{print $1}' )
                                        sne1_startlocaldate=$(cat $sne1_datum | tail -n 1 | awk -F ',' '{print $2}' )
                                        sne1_startlocaltime=$(cat $sne1_datum | tail -n 1 | awk -F ',' '{print $3}' )
                                        sne1_utc_halfsec=$(echo $sne1_utcdatetime | awk -F ':' '{print $NF}' | sed 's/Z//g')

                                        sne1_final_reading=$(cat $sne1_datum | tail -n 1| awk -F ',' '{print $NF}')
                                        snevent1_start_end_datetime=$(date --date "$(date -Iseconds -d "$sne1_startlocaldate $sne1_startlocaltime:$sne1_utc_halfsec") \
                                                + 5 seconds" +'%b %d, %Y %H:%M:%S')
                                        snevent1_utc_start_end_datetime=$(TZ=UTC date --date "$(date -Iseconds -d "$sne1_utcdatetime") \
                                                + 5 seconds" +'%Y-%m-%d %H:%M:%SZ')
                                fi

                                # Creating a data sample window that is 1 hour after the enddate to get the start reading at the end of the gap
                                startdate_1sec_after=$(TZ=UTC date --date "$(TZ=UTC date -Iseconds -d "$utcenddate") + 1 second" +'%Y-%m-%d %H:%M:%SZ' | \
                                        sed 's/ /T/g;s/:/%3A/g')
                                startdate_1hour_after=$(TZ=UTC date --date "$(TZ=UTC date -Iseconds -d "$utcenddate") + 1 hour" +'%Y-%m-%d %H:%M:%SZ' | \
                                        sed 's/ /T/g;s/:/%3A/g')

                                log "Executing python3 solnet_query.py --action=\"utc\" --node=\"$node\" --sourceids=\"$sourceids\" --startdate=\"$startdate_1sec_after\" --enddate=\"$startdate_1hour_after\" --aggregate=\"None\" --maxoutput=\"$maxoutput\" --token=\"$token\" --secret=\"$secret\" to determine SN EVENT 2"

                                # Filename where possible boundary readings at the end of the gap is stored
                                sne2_datum="data/${node}_${sourceids}_${startdate_1sec_after}_${startdate_1hour_after}_datum"
                                python3 solnet_query.py --action="utc" --node="$node" --sourceids="$sourceids" --startdate="$startdate_1sec_after" \
                                        --enddate="$startdate_1hour_after" --aggregate="None" --maxoutput="$maxoutput" \
                                        --token="$token" --secret="$secret" > $sne2_datum

                                sed -i '1d' $sne2_datum
                                log "Showing data at end border"
                                head -n 5 $sne2_datum

                                # If there is no datum after the end of the gap, final reading is 0 and the start and end time for event 2 is 5 seconds after the end date of the gap
                                if [ -z "$(cat $sne2_datum)" ] ; then
                                        snevent2_start_end_datetime=$(date --date "$(date -Iseconds -d "$localenddate") + 5 seconds" \
                                                +'%b %d, %Y %H:%M:%S')
                                        snevent2_utc_start_end_datetime=$(TZ=UTC date --date "$(date -Iseconds -d \
                                                "$utcenddate") + 5 seconds" +'%Y-%m-%d %H:%M:%SZ')

                                        sne2_start_reading=0
                                # If there is datum after the end of the gap, final reading is the first datum entry and the start and end time
                                # for event 2 is 5 seconds before the first datum entry
                                else
                                        sne2_utcdatetime=$(cat $sne2_datum | head -n 1 | awk -F ',' '{print $1}' )
                                        sne2_endlocaldate=$(cat $sne2_datum | head -n 1 | awk -F ',' '{print $2}' )
                                        sne2_endlocaltime=$(cat $sne2_datum | head -n 1 | awk -F ',' '{print $3}' )
                                        sne2_utc_halfsec=$(echo $sne2_utcdatetime | awk -F ':' '{print $NF}' | sed 's/Z//g')
                                        sne2_start_reading=$(cat $sne2_datum | head -n 1| awk -F ',' '{print $NF}')

                                        snevent2_start_end_datetime=$(date --date "$(date -Iseconds -d \
                                                "$sne2_endlocaldate $sne2_endlocaltime:$sne2_utc_halfsec") - 5 seconds" +'%b %d, %Y %H:%M:%S')
                                        snevent2_utc_start_end_datetime=$(TZ=UTC date --date "$(date -Iseconds -d \
                                                "$sne2_utcdatetime") - 5 seconds" +'%Y-%m-%d %H:%M:%SZ')
                                fi

                                # Get start reading of event 1
                                sne1_start_reading=$(head -n 2 $file_to_import | tail -n 1 | awk -F ',' '{print $NF}')

                                # Get final reading of event 2
                                sne2_final_reading=$(tail -n 1 $file_to_import | awk -F ',' '{print $NF}')

                                # Summary of Solnet Event Parameters
                                log "Solar Network Event 1"
                                log "Cause: Discontinuity due to Gap - Start Border"
                                log "Description: Discontinuity due to Gap - Start Border"
                                log "Node ID: $node"
                                log "Source ID: $sid"
                                log "Start datetime: $snevent1_start_end_datetime"
                                log "End datetime: $snevent1_start_end_datetime"
                                log "Final reading: $sne1_final_reading"
                                log "Start Reading: $sne1_start_reading"

                                log "Store Auxiliary Script for Event 1: python3 solnet_store_auxiliary.py --node $node --source \"$sid\" --type \"Reset\" --created \"$snevent1_utc_start_end_datetime\" --notes \"Discontinuity due to Gap - Start Border\" --final '{\"a\":{\"wattHours\":$sne1_final_reading}}' --start '{\"a\":{\"wattHours\":$sne1_start_reading}}' --token \"$token\" --secret \"$secret\""

                                log "Solar Network Event 2"
                                log "Cause: Discontinuity due to Gap - End Border"
                                log "Description: Discontinuity due to Gap - End Border"
                                log "Node ID: $node"
                                log "Source ID: $sid"
                                log "Start datetime: $snevent2_start_end_datetime"
                                log "End datetime: $snevent2_start_end_datetime"
                                log "Final reading: $sne2_final_reading"
                                log "Start Reading: $sne2_start_reading"

                                log "Store Auxiliary Script for Event 2: python3 solnet_store_auxiliary.py --node $node --source \"$sid\" --type \"Reset\" --created \"$snevent2_utc_start_end_datetime\" --notes \"Discontinuity due to Gap - End Border\" --final '{\"a\":{\"wattHours\":$sne2_final_reading}}' --start '{\"a\":{\"wattHours\":$sne2_start_reading}}' --token \"$token\" --secret \"$secret\""

                                ###################################################################################
                                log "Creating staged data"
                                log "Checking size of file"
                                filesizebytes=$(ls -l $file_to_import | awk '{print $5}')
                                filsesizemb=$(($filesizebytes/1048576))

                                log "Size of file: $filsesizemb"

                                if [ $filsesizemb -lt 20 ] ; then
                                        compress="disabled"
                                else
                                        file_to_import="${file_to_import}.xz"
                                        compress="enabled"
                                fi

                                log "Executing python3 solnet_import.py --node=\"$node\" --sourceids=\"$sourceids\" --timezone=\"UTC\" --compression=\"$compress\" --filepath=\"$file_to_import\" --token=\"$token\" --secret=\"$secret\" in 10 seconds. Hit Ctrl + C to Cancel"

                                sleep 10
                                jobid=$(python3 solnet_import.py --node="$node" --sourceids="$sourceids" --timezone="UTC" --compression="$compress" \
                                        --filepath="$file_to_import" --token="$token" --secret="$secret")

                                log "Executing python3 solnet_manage_jobs.py --job=\"import\" --action=\"preview\" --token=\"$token\" --secret=\"$secret\" --jobid=\"$jobid\" to preview imported data"

                                python3 solnet_manage_jobs.py --job="import" --action="preview" --token="$token" \
                                --secret="$secret" --jobid="$jobid" 2>&1 | tee -a $log_path

                                log "To apply staged data, python3 solnet_manage_jobs.py --job=\"import\" --action=\"confirm\" --token=\"$token\" --secret=\"$secret\" --jobid=\"$jobid\" will be executed"

				# Prompt user confirmation before applying staged data
                                confirm_result=$(confirm_action "Would You Like To Proceed To Apply Staged Data")


                                if [[ "$confirm_result" == "Y" ]] ; then

                                        if [ $datum_count -gt 0 ]; then

                                                log "Checking if expire process has completed."

                                                result_count=$(python3 solnet_expire.py --action="preview" --node="$node" --sourceids="$sourceids" \
                                                --localstartdate="$formatted_localstartdate" --localenddate="$formatted_localenddate" \
                                                --token="$token" --secret="$secret")

                                                if [ $result_count -eq 0 ] ; then

                                                        log "Expire result count: $result_count. Process completed."

                                                        log "Executing python3 solnet_manage_jobs.py --job=\"import\" --action=\"confirm\" --token=\"$token\" --secret=\"$secret\" --jobid=\"$jobid\" in 10 seconds. Hit CTRL+C to cancel"
                                                        sleep 10

                                                        python3 solnet_manage_jobs.py --job="import" --action="confirm" --token="$token"\
                                                                --secret="$secret" --jobid="$jobid" 2>&1 | tee -a $log_path

                                                        log "Execute python3 solnet_manage_jobs.py --job=\"import\" --action=\"list\" --token=\"$token\" --secret=\"$secret\" to view import progress"

                                                else
                                                        log "Process aborted. Expire process not completed. Run manually."
                                                        log "Once unwanted data has been deleted, execute python3 solnet_manage_jobs.py --job=\"import\" --action=\"confirm\" --token=\"$token\" --secret=\"$secret\" --jobid=\"$jobid\" in 10 seconds. Hit CTRL+C to cancel"
                                                fi
                                        else
                                                 log "Executing python3 solnet_manage_jobs.py --job=\"import\" --action=\"confirm\" --token=\"$token\" --secret=\"$secret\" --jobid=\"$jobid\" in 10 seconds. Hit CTRL+C to cancel"
                                                 sleep 10

                                                 python3 solnet_manage_jobs.py --job="import" --action="confirm" --token="$token"\
                                                         --secret="$secret" --jobid="$jobid" 2>&1 | tee -a $log_path

                                                 log "Execute python3 solnet_manage_jobs.py --job=\"import\" --action=\"list\" --token=\"$token\" --secret=\"$secret\" to view import progress"

                                        fi
                                else
                                        log "Import Process Aborted. Deleting Staged Data. Executing python3 solnet_manage_jobs.py --job=\"import\" --action=\"delete\" --token=\"$token\" --secret=\"$secret\" --jobid=\"$jobid\" in 10 seconds. Hit CTRL+C to cancel"
                                        sleep 10
                                        python3 solnet_manage_jobs.py --job="import" --action="delete" --token="$token" --secret="$secret" --jobid="$jobid" 2>&1 | tee -a $log_path
                                fi
                        fi
                fi
        else
                log "Unable to determine type of datum (GEN/PYR) from source ID provided"
                exit 1
        fi

fi
